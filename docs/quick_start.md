# å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ç¯å¢ƒ

```bash
# å…‹éš†é¡¹ç›®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
git clone <your-repo-url>
cd quant

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python simple_test.py
```

### 2. åŸºæœ¬é‡åŒ–ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
# é‡åŒ–ä¸€ä¸ªæ¨¡å‹
python quantize.py \
    --model-path /path/to/your/model \
    --output-path ./quantized_model \
    --method gptq \
    --bits 4
```

### 3. éƒ¨ç½²åˆ°vLLMï¼ˆ1åˆ†é’Ÿï¼‰

```bash
# ä½¿ç”¨éƒ¨ç½²å·¥å…·
python deploy_vllm.py --model-path ./quantized_model

# æˆ–è€…ç›´æ¥å¯åŠ¨vLLM
python -m vllm.entrypoints.openai.api_server \
    --model ./quantized_model \
    --quantization gptq
```

### 4. æµ‹è¯•APIï¼ˆ1åˆ†é’Ÿï¼‰

```bash
# æµ‹è¯•API
curl -X POST http://localhost:8000/v1/completions \
    -H "Content-Type: application/json" \
    -d '{"prompt": "Hello, how are you?", "max_tokens": 50}'
```

## ğŸ“š è¯¦ç»†ä½¿ç”¨æŒ‡å—

### æ”¯æŒçš„é‡åŒ–æ–¹æ³•

| æ–¹æ³• | æè¿° | é€‚ç”¨åœºæ™¯ | ç¤ºä¾‹å‘½ä»¤ |
|------|------|----------|----------|
| **GPTQ** | åŸºäºHessiançŸ©é˜µçš„é‡åŒ– | é«˜è´¨é‡é‡åŒ– | `--method gptq` |
| **AWQ** | Activation-awareé‡åŒ– | æ¿€æ´»æ„ŸçŸ¥é‡åŒ– | `--method awq` |
| **MinMax** | åŸºç¡€çº¿æ€§é‡åŒ– | å¿«é€ŸåŸå‹ | `--method minmax` |

### å¸¸ç”¨å‚æ•°

```bash
python quantize.py \
    --model-path /path/to/model \      # åŸå§‹æ¨¡å‹è·¯å¾„
    --output-path /path/to/output \    # è¾“å‡ºè·¯å¾„
    --method gptq \                    # é‡åŒ–æ–¹æ³•
    --bits 4 \                         # é‡åŒ–ä½æ•° (2/3/4/8/16)
    --group-size 128 \                 # é‡åŒ–ç»„å¤§å°
    --layer-wise \                     # é€å±‚é‡åŒ–
    --layers 0,1,2 \                   # æŒ‡å®šå±‚
    --outlier-suppression smooth_quant \ # ç¦»ç¾¤å€¼æŠ‘åˆ¶
    --config configs/gptq_config.yaml \ # é…ç½®æ–‡ä»¶
    --verbose                          # è¯¦ç»†è¾“å‡º
```

### é«˜çº§åŠŸèƒ½

#### 1. é€å±‚é‡åŒ–

```bash
# åªé‡åŒ–å‰3å±‚
python quantize.py \
    --model-path /path/to/model \
    --output-path /path/to/output \
    --method gptq \
    --layer-wise \
    --layers 0,1,2
```

#### 2. ä½¿ç”¨ç¦»ç¾¤å€¼æŠ‘åˆ¶

```bash
# ä½¿ç”¨SmoothQuantæé«˜è´¨é‡
python quantize.py \
    --model-path /path/to/model \
    --output-path /path/to/output \
    --method gptq \
    --outlier-suppression smooth_quant \
    --calibration-dataset /path/to/calibration_data
```

#### 3. è‡ªå®šä¹‰é…ç½®

```bash
# ä½¿ç”¨é…ç½®æ–‡ä»¶
python quantize.py \
    --model-path /path/to/model \
    --output-path /path/to/output \
    --method gptq \
    --config configs/gptq_config.yaml
```

## ğŸ”§ é…ç½®è¯´æ˜

### åŸºæœ¬é…ç½®ç¤ºä¾‹

```yaml
# configs/gptq_config.yaml
quantization:
  method: "gptq"
  bits: 4
  group_size: 128
  layer_wise: false
  outlier_suppression: null

model:
  trust_remote_code: true
  device_map: "auto"
  torch_dtype: "float16"

calibration:
  dataset: null
  num_samples: 100
  batch_size: 1
  max_length: 2048

output:
  save_format: "safetensors"
  save_quantization_config: true
```

### ä¸åŒé‡åŒ–æ–¹æ³•çš„é…ç½®

#### GPTQé…ç½®
```yaml
quantization:
  method: "gptq"
  gptq:
    damp_percent: 0.01
    desc_act: false
    static_groups: false
    sym: true
    true_sequential: true
```

#### AWQé…ç½®
```yaml
quantization:
  method: "awq"
  awq:
    zero_point: true
    q_type: "asym"
    w_bit: 4
    a_bit: 8
```

#### MinMaxé…ç½®
```yaml
quantization:
  method: "minmax"
  minmax:
    symmetric: false
    per_channel: false
    dynamic_range: "minmax"
```

## ğŸš€ vLLMéƒ¨ç½²

### è‡ªåŠ¨éƒ¨ç½²

```bash
# ä½¿ç”¨éƒ¨ç½²å·¥å…·ï¼ˆæ¨èï¼‰
python deploy_vllm.py --model-path ./quantized_model
```

### æ‰‹åŠ¨éƒ¨ç½²

```bash
# GPTQæ¨¡å‹
python -m vllm.entrypoints.openai.api_server \
    --model ./quantized_model \
    --quantization gptq

# AWQæ¨¡å‹
python -m vllm.entrypoints.openai.api_server \
    --model ./quantized_model \
    --quantization awq

# MinMaxæ¨¡å‹
python -m vllm.entrypoints.openai.api_server \
    --model ./quantized_model \
    --quantization minmax
```

### Python APIä½¿ç”¨

```python
from vllm import LLM, SamplingParams

# åŠ è½½æ¨¡å‹
llm = LLM(
    model="./quantized_model",
    quantization="gptq"  # æˆ– "awq", "minmax"
)

# è®¾ç½®å‚æ•°
sampling_params = SamplingParams(
    temperature=0.7,
    top_p=0.95,
    max_tokens=100
)

# ç”Ÿæˆæ–‡æœ¬
outputs = llm.generate("Hello, how are you?", sampling_params)
print(outputs[0].outputs[0].text)
```

### HTTP APIä½¿ç”¨

```bash
# æ–‡æœ¬è¡¥å…¨
curl -X POST http://localhost:8000/v1/completions \
    -H "Content-Type: application/json" \
    -d '{
        "prompt": "Hello, how are you?",
        "max_tokens": 50,
        "temperature": 0.7
    }'

# èŠå¤©è¡¥å…¨
curl -X POST http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "messages": [
            {"role": "user", "content": "Hello, how are you?"}
        ],
        "max_tokens": 50,
        "temperature": 0.7
    }'
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**A**: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
- ä½¿ç”¨æ›´å°çš„é‡åŒ–ä½æ•°ï¼š`--bits 2` æˆ– `--bits 3`
- ä½¿ç”¨é€å±‚é‡åŒ–ï¼š`--layer-wise --layers 0,1,2`
- å‡å°‘batch sizeï¼šåœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® `batch_size: 1`

### Q2: é‡åŒ–é€Ÿåº¦å¤ªæ…¢ï¼Ÿ

**A**: ä¼˜åŒ–å»ºè®®ï¼š
- ä½¿ç”¨MinMaxé‡åŒ–ï¼š`--method minmax`
- å‡å°‘æ ¡å‡†æ•°æ®ï¼š`num_samples: 50`
- ä½¿ç”¨æ›´å°çš„ç»„å¤§å°ï¼š`--group-size 64`

### Q3: é‡åŒ–è´¨é‡ä¸å¥½ï¼Ÿ

**A**: æé«˜è´¨é‡çš„æ–¹æ³•ï¼š
- ä½¿ç”¨ç¦»ç¾¤å€¼æŠ‘åˆ¶ï¼š`--outlier-suppression smooth_quant`
- å¢åŠ æ ¡å‡†æ•°æ®é‡
- ä½¿ç”¨æ›´é«˜çš„é‡åŒ–ä½æ•°ï¼š`--bits 8`

### Q4: vLLMéƒ¨ç½²å¤±è´¥ï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- ç¡®è®¤é‡åŒ–æ–¹æ³•æ­£ç¡®ï¼š`--quantization gptq/awq/minmax`
- æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
- æŸ¥çœ‹vLLMé…ç½®æ–‡ä»¶ï¼š`vllm_config.json`

### Q5: å¦‚ä½•æ·»åŠ æ–°çš„é‡åŒ–ç®—æ³•ï¼Ÿ

**A**: å‚è€ƒæ‰©å±•æŒ‡å—ï¼š
```bash
# æŸ¥çœ‹è¯¦ç»†æŒ‡å—
cat docs/extension_guide.md

# æŸ¥çœ‹æ¶æ„æ–‡æ¡£
cat docs/4plus1_architecture.md
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| é‡åŒ–æ–¹æ³• | é€Ÿåº¦ | è´¨é‡ | å†…å­˜å ç”¨ | é€‚ç”¨åœºæ™¯ |
|----------|------|------|----------|----------|
| **GPTQ** | ä¸­ç­‰ | é«˜ | ä¸­ç­‰ | ç”Ÿäº§ç¯å¢ƒ |
| **AWQ** | å¿« | é«˜ | ä½ | èµ„æºå—é™ |
| **MinMax** | æœ€å¿« | ä¸­ç­‰ | æœ€ä½ | å¿«é€ŸåŸå‹ |

## ğŸ”— ç›¸å…³é“¾æ¥

- [å®Œæ•´æ–‡æ¡£](docs/4plus1_architecture.md) - 4+1æ¶æ„è§†å›¾
- [æ‰©å±•æŒ‡å—](docs/extension_guide.md) - å¼€å‘æ‰©å±•
- [é…ç½®ç¤ºä¾‹](configs/) - é…ç½®æ–‡ä»¶
- [æµ‹è¯•è„šæœ¬](tests/) - åŠŸèƒ½æµ‹è¯•

## ğŸ’¡ æœ€ä½³å®è·µ

1. **é€‰æ‹©åˆé€‚çš„é‡åŒ–æ–¹æ³•**ï¼š
   - ç”Ÿäº§ç¯å¢ƒï¼šGPTQæˆ–AWQ
   - å¿«é€Ÿæµ‹è¯•ï¼šMinMax
   - èµ„æºå—é™ï¼šAWQ

2. **ä¼˜åŒ–é‡åŒ–å‚æ•°**ï¼š
   - ä»4ä½å¼€å§‹ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´
   - ä½¿ç”¨128çš„ç»„å¤§å°ä½œä¸ºèµ·ç‚¹
   - å¯¹äºé‡è¦æ¨¡å‹ä½¿ç”¨ç¦»ç¾¤å€¼æŠ‘åˆ¶

3. **éƒ¨ç½²å»ºè®®**ï¼š
   - ä½¿ç”¨éƒ¨ç½²å·¥å…·è‡ªåŠ¨æ£€æµ‹é‡åŒ–æ–¹æ³•
   - åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨é…ç½®æ–‡ä»¶
   - å®šæœŸå¤‡ä»½åŸå§‹æ¨¡å‹

4. **ç›‘æ§å’Œè°ƒè¯•**ï¼š
   - ä½¿ç”¨`--verbose`æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
   - æ£€æŸ¥é‡åŒ–æŠ¥å‘Šäº†è§£æ•ˆæœ
   - å¯¹æ¯”ä¸åŒé‡åŒ–æ–¹æ³•çš„ç»“æœ 